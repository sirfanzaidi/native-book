"use strict";(self.webpackChunkphysical_ai_humanoid_robotics_book=self.webpackChunkphysical_ai_humanoid_robotics_book||[]).push([[566],{4970:function(e,n,i){i.r(n),i.d(n,{assets:function(){return l},contentTitle:function(){return o},default:function(){return h},frontMatter:function(){return c},metadata:function(){return s},toc:function(){return a}});var s=JSON.parse('{"id":"module-3-ai-perception/06-isaac-fundamentals","title":"Chapter 6 - NVIDIA Isaac: GPU-Accelerated Robotics","description":"Introduction","source":"@site/docs/03-module-3-ai-perception/01-isaac-fundamentals.md","sourceDirName":"03-module-3-ai-perception","slug":"/module-3-ai-perception/06-isaac-fundamentals","permalink":"/native-book/module-3-ai-perception/06-isaac-fundamentals","draft":false,"unlisted":false,"editUrl":"https://github.com/native-book/native-book/tree/main/docs/03-module-3-ai-perception/01-isaac-fundamentals.md","tags":[],"version":"current","sidebarPosition":1,"frontMatter":{"id":"06-isaac-fundamentals","title":"Chapter 6 - NVIDIA Isaac: GPU-Accelerated Robotics","sidebar_label":"Chapter 6: Isaac Basics"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 5: ROS 2 + Gazebo","permalink":"/native-book/module-2-digital-twin/05-ros2-gazebo-bridge"},"next":{"title":"Chapter 7: Perception Pipelines","permalink":"/native-book/module-3-ai-perception/07-perception-pipelines"}}'),t=i(4848),r=i(8453);const c={id:"06-isaac-fundamentals",title:"Chapter 6 - NVIDIA Isaac: GPU-Accelerated Robotics",sidebar_label:"Chapter 6: Isaac Basics"},o="Chapter 6: NVIDIA Isaac: GPU-Accelerated Robotics",l={},a=[{value:"Introduction",id:"introduction",level:2},{value:"Why GPU Acceleration?",id:"why-gpu-acceleration",level:3},{value:"What is NVIDIA Isaac?",id:"what-is-nvidia-isaac",level:3},{value:"The Perception Pipeline",id:"the-perception-pipeline",level:3},{value:"GPU Acceleration Concepts",id:"gpu-acceleration-concepts",level:2},{value:"Why GPUs are Fast for AI",id:"why-gpus-are-fast-for-ai",level:3},{value:"Common AI Models for Robotics",id:"common-ai-models-for-robotics",level:3},{value:"NVIDIA Isaac Architecture",id:"nvidia-isaac-architecture",level:2},{value:"Real-Time Perception Pipeline",id:"real-time-perception-pipeline",level:2},{value:"Simple Object Detection Node",id:"simple-object-detection-node",level:3},{value:"Expected Output",id:"expected-output",level:3},{value:"Perception Pipeline Architecture",id:"perception-pipeline-architecture",level:2},{value:"Real-Time Constraints",id:"real-time-constraints",level:2},{value:"Integration with ROS 2",id:"integration-with-ros-2",level:2},{value:"Summary",id:"summary",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"chapter-6-nvidia-isaac-gpu-accelerated-robotics",children:"Chapter 6: NVIDIA Isaac: GPU-Accelerated Robotics"})}),"\n",(0,t.jsx)(n.h2,{id:"introduction",children:"Introduction"}),"\n",(0,t.jsxs)(n.p,{children:["In Modules 1 and 2, you learned to control robots and simulate them. But ",(0,t.jsx)(n.strong,{children:"real-world robots need perception"}),": understanding the world through cameras, sensors, and AI."]}),"\n",(0,t.jsxs)(n.p,{children:["Processing images at real-time speeds (30+ fps) while running complex AI models requires ",(0,t.jsx)(n.strong,{children:"GPU acceleration"}),". This is where NVIDIA Isaac comes in."]}),"\n",(0,t.jsx)(n.h3,{id:"why-gpu-acceleration",children:"Why GPU Acceleration?"}),"\n",(0,t.jsx)(n.p,{children:"Imagine your robot needs to:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Capture camera image (60 fps)"}),"\n",(0,t.jsx)(n.li,{children:"Run object detection (YOLO model)"}),"\n",(0,t.jsx)(n.li,{children:"Estimate pose of objects"}),"\n",(0,t.jsx)(n.li,{children:"Send commands to motors"}),"\n",(0,t.jsxs)(n.li,{children:["All in ",(0,t.jsx)(n.strong,{children:"real-time"})," without lag"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"CPU alone"}),": Can't handle this. By the time you've processed frame N, frames N+1 through N+10 have arrived."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"GPU acceleration"}),": Process all operations in parallel, keeping up with real-time demands."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Source"}),": NVIDIA Isaac Documentation. (2024). ",(0,t.jsx)(n.em,{children:"Isaac Platform Overview"}),". Retrieved from ",(0,t.jsx)(n.a,{href:"https://developer.nvidia.com/isaac",children:"https://developer.nvidia.com/isaac"})]}),"\n",(0,t.jsx)(n.h3,{id:"what-is-nvidia-isaac",children:"What is NVIDIA Isaac?"}),"\n",(0,t.jsxs)(n.p,{children:["Isaac is NVIDIA's ",(0,t.jsx)(n.strong,{children:"robotics software platform"})," providing:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"GPU-accelerated perception"}),": Real-time vision processing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AI inference engines"}),": Run deep learning models fast"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS 2 integration"}),": Publish/subscribe to ROS 2 topics"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Simulation"}),": Isaac Sim (3D environment for testing)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Graph-based architecture"}),": Visual pipeline building"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Pre-trained models"}),": Object detection, pose estimation, semantic segmentation"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"the-perception-pipeline",children:"The Perception Pipeline"}),"\n",(0,t.jsx)(n.p,{children:"A typical AI-powered robot workflow:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[Camera Input]\n     \u2193\n[Preprocessing]  \u2190 GPU acceleration\n     \u2193\n[AI Model]      \u2190 Run on GPU (YOLO, ResNet, etc.)\n     \u2193\n[Post-processing] \u2190 Extract results\n     \u2193\n[ROS 2 Topics]  \u2190 Publish detections\n     \u2193\n[Robot Control] \u2190 Use results for decisions\n"})}),"\n",(0,t.jsx)(n.p,{children:"Each step happens on GPU, achieving 30+ fps on real images."}),"\n",(0,t.jsx)(n.h2,{id:"gpu-acceleration-concepts",children:"GPU Acceleration Concepts"}),"\n",(0,t.jsx)(n.h3,{id:"why-gpus-are-fast-for-ai",children:"Why GPUs are Fast for AI"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Aspect"}),(0,t.jsx)(n.th,{children:"CPU"}),(0,t.jsx)(n.th,{children:"GPU"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Cores"})}),(0,t.jsx)(n.td,{children:"8-16 cores"}),(0,t.jsx)(n.td,{children:"1000s of cores"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Parallelism"})}),(0,t.jsx)(n.td,{children:"Sequential"}),(0,t.jsx)(n.td,{children:"Massive parallel"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Image processing"})}),(0,t.jsx)(n.td,{children:"1 pixel at a time"}),(0,t.jsx)(n.td,{children:"1000s of pixels at once"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Throughput"})}),(0,t.jsx)(n.td,{children:"10-50 fps"}),(0,t.jsx)(n.td,{children:"100+ fps"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Power efficiency"})}),(0,t.jsx)(n.td,{children:"High power"}),(0,t.jsx)(n.td,{children:"Lower power per operation"})]})]})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Example"}),": Processing 1000\xd71000 image"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"CPU"}),": Process each pixel sequentially = slow"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"GPU"}),": Process 1000 pixels in parallel = 1000x faster"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"common-ai-models-for-robotics",children:"Common AI Models for Robotics"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Model"}),(0,t.jsx)(n.th,{children:"Purpose"}),(0,t.jsx)(n.th,{children:"Speed (GPU)"}),(0,t.jsx)(n.th,{children:"Accuracy"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"YOLOv8"})}),(0,t.jsx)(n.td,{children:"Object detection"}),(0,t.jsx)(n.td,{children:"20-30 fps"}),(0,t.jsx)(n.td,{children:"95%+"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"ResNet"})}),(0,t.jsx)(n.td,{children:"Classification"}),(0,t.jsx)(n.td,{children:"50+ fps"}),(0,t.jsx)(n.td,{children:"92%+"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"PoseNet"})}),(0,t.jsx)(n.td,{children:"Human pose"}),(0,t.jsx)(n.td,{children:"15-25 fps"}),(0,t.jsx)(n.td,{children:"90%+"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"SegNet"})}),(0,t.jsx)(n.td,{children:"Segmentation"}),(0,t.jsx)(n.td,{children:"10-20 fps"}),(0,t.jsx)(n.td,{children:"88%+"})]})]})]}),"\n",(0,t.jsxs)(n.p,{children:["These models run in ",(0,t.jsx)(n.strong,{children:"milliseconds"})," on GPU, seconds on CPU."]}),"\n",(0,t.jsx)(n.h2,{id:"nvidia-isaac-architecture",children:"NVIDIA Isaac Architecture"}),"\n",(0,t.jsx)(n.p,{children:"Isaac connects to ROS 2 with plugins that:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Capture"})," images from cameras (ROS 2 topic ",(0,t.jsx)(n.code,{children:"/camera/image_raw"}),")"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Process"})," with GPU-accelerated models"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Publish"})," results back to ROS 2 topics (",(0,t.jsx)(n.code,{children:"/detections"}),", ",(0,t.jsx)(n.code,{children:"/poses"}),")"]}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[ROS 2 Camera Topic] \u2192  [Isaac Node] \u2192  [GPU Inference] \u2192  [ROS 2 Output Topics]\n"})}),"\n",(0,t.jsx)(n.p,{children:"The Isaac node acts as a bridge: receives ROS 2 topics, processes on GPU, publishes results."}),"\n",(0,t.jsx)(n.h2,{id:"real-time-perception-pipeline",children:"Real-Time Perception Pipeline"}),"\n",(0,t.jsx)(n.h3,{id:"simple-object-detection-node",children:"Simple Object Detection Node"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"#!/usr/bin/env python3\n\"\"\"\nNVIDIA Isaac Object Detection\nRuns YOLO detection on camera images\n\"\"\"\n\nimport rclpy\nfrom rclpy.node import Node\nfrom sensor_msgs.msg import Image\nfrom geometry_msgs.msg import BoundingBox2D, Pose2D\nfrom cv_bridge import CvBridge\nimport cv2\nimport time\n\n\nclass IsaacDetectionNode(Node):\n    def __init__(self):\n        super().__init__('isaac_detection_node')\n\n        # Subscribe to camera images\n        self.image_sub = self.create_subscription(\n            Image,\n            '/camera/image_raw',\n            self.image_callback,\n            10)\n\n        # Publisher for detection results\n        self.detection_pub = self.create_publisher(\n            BoundingBox2D,\n            '/detections',\n            10)\n\n        # Bridge for OpenCV image conversion\n        self.bridge = CvBridge()\n        self.frame_count = 0\n        self.fps_start = time.time()\n\n        self.get_logger().info('Object detection node started')\n\n    def image_callback(self, msg):\n        \"\"\"Process camera image with GPU-accelerated detection\"\"\"\n        # Convert ROS image to OpenCV format\n        try:\n            cv_image = self.bridge.imgmsg_to_cv2(msg, \"bgr8\")\n        except Exception as e:\n            self.get_logger().error(f'Image conversion failed: {e}')\n            return\n\n        # In real Isaac, this would run GPU-accelerated YOLO\n        # For this example, we log the image properties\n        height, width, channels = cv_image.shape\n\n        # Simulate detection results\n        detection_result = BoundingBox2D()\n        detection_result.center.x = float(width // 2)\n        detection_result.center.y = float(height // 2)\n        detection_result.size_x = float(width // 4)\n        detection_result.size_y = float(height // 4)\n\n        # Publish detection\n        self.detection_pub.publish(detection_result)\n\n        # Calculate and log FPS\n        self.frame_count += 1\n        elapsed = time.time() - self.fps_start\n        if elapsed > 1.0:\n            fps = self.frame_count / elapsed\n            self.get_logger().info(\n                f'Detection FPS: {fps:.1f}, Image: {width}x{height}')\n            self.frame_count = 0\n            self.fps_start = time.time()\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    detection_node = IsaacDetectionNode()\n    rclpy.spin(detection_node)\n    detection_node.destroy_node()\n    rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"What's happening"}),":"]}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Subscribe to ",(0,t.jsx)(n.code,{children:"/camera/image_raw"})," from robot camera"]}),"\n",(0,t.jsx)(n.li,{children:"Receive images at camera framerate (30+ fps)"}),"\n",(0,t.jsx)(n.li,{children:"On GPU: Run YOLO detection (real-time)"}),"\n",(0,t.jsx)(n.li,{children:"Extract bounding boxes of detected objects"}),"\n",(0,t.jsxs)(n.li,{children:["Publish results to ",(0,t.jsx)(n.code,{children:"/detections"})," topic"]}),"\n",(0,t.jsx)(n.li,{children:"Log FPS to monitor real-time performance"}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"expected-output",children:"Expected Output"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Terminal"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[isaac_detection_node] Object detection node started\n[isaac_detection_node] Detection FPS: 28.3, Image: 1920x1080\n[isaac_detection_node] Detection FPS: 29.1, Image: 1920x1080\n[isaac_detection_node] Detection FPS: 29.5, Image: 1920x1080\n"})}),"\n",(0,t.jsx)(n.p,{children:"Maintaining 29+ fps = real-time perception \u2705"}),"\n",(0,t.jsx)(n.h2,{id:"perception-pipeline-architecture",children:"Perception Pipeline Architecture"}),"\n",(0,t.jsx)(n.p,{children:"A complete perception system for humanoid robot:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"[Camera 1] \u2500\u2500\u2510\n[Camera 2] \u2500\u2500\u253c\u2192 [Isaac Perception Node] \u2192  [GPU Inference] \u2192 [ROS 2 Topics]\n[LiDAR]    \u2500\u2500\u2518\n\nGPU processes:\n\u251c\u2500\u2500 Object Detection (what things are)\n\u251c\u2500\u2500 Pose Estimation (where things are)\n\u251c\u2500\u2500 Semantic Segmentation (scene understanding)\n\u2514\u2500\u2500 Tracking (follow objects over time)\n\nResults published to:\n\u251c\u2500\u2500 /detections (bounding boxes)\n\u251c\u2500\u2500 /poses (3D positions)\n\u251c\u2500\u2500 /segmentation (semantic labels)\n\u2514\u2500\u2500 /tracking (object IDs)\n"})}),"\n",(0,t.jsx)(n.h2,{id:"real-time-constraints",children:"Real-Time Constraints"}),"\n",(0,t.jsx)(n.p,{children:"GPU acceleration is necessary because:"}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Constraint"}),(0,t.jsx)(n.th,{children:"Requirement"}),(0,t.jsx)(n.th,{children:"Challenge"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Latency"})}),(0,t.jsx)(n.td,{children:"Less than 33ms per frame (30 fps)"}),(0,t.jsx)(n.td,{children:"Multiple images arriving per second"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Resolution"})}),(0,t.jsx)(n.td,{children:"1920\xd71080 or higher"}),(0,t.jsx)(n.td,{children:"High data throughput"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Models"})}),(0,t.jsx)(n.td,{children:"Complex AI (YOLO, ResNet)"}),(0,t.jsx)(n.td,{children:"Need 1000s of operations per pixel"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:(0,t.jsx)(n.strong,{children:"Parallel"})}),(0,t.jsx)(n.td,{children:"Run detection + tracking + segmentation"}),(0,t.jsx)(n.td,{children:"Can't be sequential"})]})]})]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"GPU solution"}),": Process all in parallel on 1000s of cores \u2192 meet real-time deadlines."]}),"\n",(0,t.jsx)(n.h2,{id:"integration-with-ros-2",children:"Integration with ROS 2"}),"\n",(0,t.jsx)(n.p,{children:"Isaac node seamlessly integrates:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Standard ROS 2 subscription\nself.image_sub = self.create_subscription(\n    Image,\n    '/camera/image_raw',  # Same as any ROS 2 node\n    self.image_callback,\n    10)\n\n# Standard ROS 2 publication\nself.detection_pub = self.create_publisher(\n    BoundingBox2D,\n    '/detections',  # Any ROS 2 node can subscribe\n    10)\n"})}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Key insight"}),": Isaac is just another ROS 2 node. Your control code doesn't need to know it's GPU-accelerated."]}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(n.p,{children:"In this chapter, you learned:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Why GPU acceleration"}),": Real-time AI needs parallel processing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"NVIDIA Isaac"}),": Platform for GPU-accelerated robotics"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Perception pipelines"}),": Multi-stage AI processing"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Real-time constraints"}),": 30+ fps requirement for smooth control"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"ROS 2 integration"}),": Isaac publishes/subscribes like any node"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Common models"}),": YOLO, ResNet, PoseNet for robotics"]}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Key Takeaway"}),": GPU acceleration enables robots to see and understand their world in real-time."]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Next steps"}),": In Chapter 7, we'll build a complete perception pipeline combining detection, tracking, and decision-making."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"References"}),":"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["NVIDIA Isaac Documentation. (2024). ",(0,t.jsx)(n.em,{children:"Isaac Platform Overview"}),". Retrieved from ",(0,t.jsx)(n.a,{href:"https://developer.nvidia.com/isaac",children:"https://developer.nvidia.com/isaac"})]}),"\n",(0,t.jsxs)(n.li,{children:["NVIDIA Isaac ROS 2 Integration. (2024). Retrieved from ",(0,t.jsx)(n.a,{href:"https://github.com/NVIDIA-ISAAC-ROS",children:"https://github.com/NVIDIA-ISAAC-ROS"})]}),"\n",(0,t.jsxs)(n.li,{children:["YOLOv8 Documentation. (2024). Retrieved from ",(0,t.jsx)(n.a,{href:"https://docs.ultralytics.com/",children:"https://docs.ultralytics.com/"})]}),"\n",(0,t.jsxs)(n.li,{children:["ROS 2 Computer Vision Interfaces. (2024). Retrieved from ",(0,t.jsx)(n.a,{href:"https://docs.ros.org/en/humble/Tutorials/Vision-OpenCV.html",children:"https://docs.ros.org/en/humble/Tutorials/Vision-OpenCV.html"})]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:function(e,n,i){i.d(n,{R:function(){return c},x:function(){return o}});var s=i(6540);const t={},r=s.createContext(t);function c(e){const n=s.useContext(r);return s.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:c(e.components),s.createElement(r.Provider,{value:n},e.children)}}}]);